# Universal Speech Assessment Model

This repository aims to collect all available speech asessment models (with the github page) including speech quality and intelligibility prediction models.

## Speech Quality Prediction Models
We collect both human-based and objective-based speech quality prediction model. 

### 1. Human-based Speech Quality Prediction 
### 1. A. MOS Prediction Model
- Dataset:  VCC2018 

- Available Model : 

  - MOSNet: Deep Learning based Objective Assessment for Voice Conversion <a href="https://github.com/lochenchou/MOSNet" target="_blank">[code]</a>
<a href="https://arxiv.org/abs/1904.08352" target="_blank">[paper]</a>

  - MBNet: MOS Prediction for Synthesized Speech with Mean-Bias Network <a href="https://github.com/sky1456723/Pytorch-MBNet" target="_blank">[code]</a>
<a href="https://arxiv.org/abs/2103.00110" target="_blank">[paper]</a>

  - Utilizing Self-supervised Representations for MOS Prediction <a href="https://github.com/s3prl/s3prl/tree/master/s3prl/downstream/mos_predictiont" target="_blank">[code]</a>
<a href="https://paperswithcode.com/paper/utilizing-self-supervised-representations-for" target="_blank">[paper]</a>

  - LDNet: Unified Listener Dependent Modeling in MOS Prediction for Synthetic Speech <a href="https://github.com/unilight/LDNet" target="_blank">[code]</a>
<a href="https://arxiv.org/pdf/2110.09103.pdf" target="_blank">[paper]</a>

- Dataset:  TMHINT-QI

- Available Model:

  - Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment Model with Cross-Domain Features <a href="https://github.com/dhimasryan/MOSA-Net-Cross-Domain" target="_blank">[code]</a>
<a href="https://ieeexplore.ieee.org/document/9905733" target="_blank">[paper]</a>

  - InQSS: a speech intelligibility and quality assessment model using a multi-task learning network <a href="https://github.com/yuwchen/InQSS" target="_blank">[code]</a>
<a href="https://arxiv.org/abs/2111.02585" target="_blank">[paper]</a>

- Dataset:  VoiceMOS Challenge

- Available Model:

  - Generalization Ability of MOS Prediction Networks <a href="https://github.com/nii-yamagishilab/mos-finetune-ssl/blob/main/VoiceMOS_baseline_README.md" target="_blank">[code]</a>
<a href="https://arxiv.org/abs/2110.02635" target="_blank">[paper]</a>

  - LDNet: Unified Listener Dependent Modeling in MOS Prediction for Synthetic Speech <a href="https://github.com/unilight/LDNet/blob/main/VoiceMOS_baseline_README.md" target="_blank">[code]</a>
<a href="https://arxiv.org/pdf/2110.09103.pdf" target="_blank">[paper]</a>

  - Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment Model with Cross-Domain Features <a href="https://github.com/dhimasryan/MOSA-Net-Cross-Domain/blob/main/VoiceMOS_Baseline_README.md" target="_blank">[code]</a>
<a href="https://ieeexplore.ieee.org/document/9905733" target="_blank">[paper]</a>

  - UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022 <a href="https://github.com/sarulab-speech/UTMOS22" target="_blank">[code]</a>
<a href="https://arxiv.org/pdf/2204.02152" target="_blank">[paper]</a>


- Dataset:  Non-intrusive Objective Speech Quality Assessment (NISQA) Challenge for Online Conferencing Applications

- Available Model:



<!--
**speechassess/speechassess** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
